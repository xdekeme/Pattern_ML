{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 3 - Support Vector Machines\n",
    "\n",
    "A SVM classifier builds a set of hyper-planes to try and separate the data by maximizing the distance between the borders and the data points.\n",
    "\n",
    "![SVM](http://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png \"Decision border in an SVM\")\n",
    "\n",
    "This separation is generally not possible to achieve in the original data space. Therefore, the first step of the SVM is to project the data into a high or infinite dimensions space in which this linear separation can be done. The projection can be done with linear, polynomial, or more comonly \"RBF\" kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, evaluate_classifier, get_hog_image\n",
    "\n",
    "dataset = CIFAR10('./CIFAR10/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a simple SVM** using [the SVC (Support Vector Classfiication) from sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC). \n",
    "**Train** it on the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive model: 0.816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# -- Your code here -- #\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "split_val = 0.1\n",
    "len_dataset = int(split_val*len(dataset.train[\"hog\"]))\n",
    "train_X = dataset.train[\"hog\"][:-len_dataset]\n",
    "train_Y = dataset.train[\"labels\"][:-len_dataset]\n",
    "val_X = dataset.train[\"hog\"][-len_dataset:]\n",
    "val_Y = dataset.train[\"labels\"][-len_dataset:]\n",
    "\n",
    "model = SVC()\n",
    "model.fit(train_X, train_Y)\n",
    "pred_model = model.predict(val_X)\n",
    "score_model = accuracy_score(val_Y, pred_model)\n",
    "print(f\"Predictive model: {score_model}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the classifier**. How many support vectors are there? What are support vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7930, 256)\n",
      "[2483 3193 2254]\n"
     ]
    }
   ],
   "source": [
    "all_support_vectors = model.support_vectors_ #Each line = 1 \"Support Vector\" ; 1024 columns forming a 32x32 image \n",
    "vectors_per_class = model.n_support_ #Number of \"Support Vector\" for each class\n",
    "\n",
    "# -- Your code here -- #\n",
    "print(all_support_vectors.shape)\n",
    "print(vectors_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to find the best \"C\" (error penalty) and \"gamma\" parameters** using cross-validation. What influence does \"C\" have on the number of support vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'gamma' parameter of SVC must be a str among {'scale', 'auto'} or a float in the range [0.0, inf). Got <class 'float'> instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.813      0.5968            nan 0.81926667 0.5968            nan\n",
      " 0.82326667 0.5968            nan 0.82686667 0.5968            nan\n",
      " 0.82546667 0.5968            nan 0.82473333 0.70533333        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result model:  0.8268666666666666\n",
      "Best parameters model:  {'C': 5, 'gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "# -- Your code here -- #\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, y = dataset.train[\"hog\"], dataset.train[\"labels\"]\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 1.5, 2, 5, 10, 100],\n",
    "    'gamma': [\"scale\", \"auto\", float],\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=skf, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best result model: \", grid_search.best_score_)\n",
    "print(\"Best parameters model: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "25 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'gamma' parameter of SVC must be a str among {'scale', 'auto'} or a float in the range [0.0, inf). Got <class 'float'> instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/xavierdekeme/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.81866667 0.59413333        nan 0.8244     0.59413333        nan\n",
      " 0.8264     0.59413333        nan 0.8284     0.59593333        nan\n",
      " 0.8262     0.6316            nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result model:  0.8284\n",
      "Best parameters model:  {'C': 5, 'gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.80) \n",
    "\n",
    "X, y = dataset.train[\"hog\"], dataset.train[\"labels\"]\n",
    "X_train_pca = pca.fit_transform(X)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 1.5, 2, 5, 10],\n",
    "    'gamma': [\"scale\", \"auto\", float],\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=skf, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_pca, y)\n",
    "\n",
    "print(\"Best result model: \", grid_search.best_score_)\n",
    "print(\"Best parameters model: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive best parameters tree (raw data): 0.83\n",
      "[[865 103  32]\n",
      " [120 779 101]\n",
      " [ 40 114 846]]\n",
      "Predictive best parameters tree (after PCA): 0.8336666666666667\n",
      "[[863 104  33]\n",
      " [111 791  98]\n",
      " [ 38 115 847]]\n"
     ]
    }
   ],
   "source": [
    "#Comparison of results based on the two hyper-parameters found\n",
    "clf_model1 = SVC(C=5, gamma=\"scale\")\n",
    "clf_model1.fit(dataset.train['hog'], dataset.train['labels'])\n",
    "pred_model1 = clf_model1.predict(dataset.test[\"hog\"])\n",
    "score_model1 = accuracy_score(dataset.test[\"labels\"], pred_model1)\n",
    "print(f\"Predictive best parameters tree (raw data): {score_model1}\") #Predictive based on the testing/validation data\n",
    "cm_model1= confusion_matrix(dataset.test[\"labels\"], pred_model1)\n",
    "print(cm_model1)\n",
    "\n",
    "pca = PCA(n_components=0.80)  \n",
    "X_train_pca = pca.fit_transform(dataset.train['hog'])\n",
    "X_test_pca = pca.transform(dataset.test['hog'])\n",
    "clf_model2 = SVC(C=5, gamma=\"scale\")\n",
    "clf_model2.fit(X_train_pca, dataset.train['labels'])\n",
    "pred_model2 = clf_model2.predict(X_test_pca)\n",
    "score_model2 = accuracy_score(dataset.test[\"labels\"], pred_model2)\n",
    "print(f\"Predictive best parameters tree (after PCA): {score_model2}\") #Predictive based on the testing/validation data\n",
    "cm_model2= confusion_matrix(dataset.test[\"labels\"], pred_model2)\n",
    "print(cm_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing algorithms\n",
    "\n",
    "Using the best hyper-parameters that you found for each of the algorithms (kNN, Decision Trees, Random Forests, MLP, SVM):\n",
    "\n",
    "* Re-train the models on the full training set.\n",
    "* Compare their results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- Your code here -- #\n",
    "#Already done in each TP"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
